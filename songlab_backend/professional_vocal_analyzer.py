"""
ì „ë¬¸ ë³´ì»¬ ë¶„ì„ê¸° - ì „ì—­ ì„ ëª…ë„/ë°ê¸°/ê±°ì¹¨ ë¶„ì„
ëª©í‘œ íŒŒì´í”„ë¼ì¸ ì™„ì „ êµ¬í˜„
"""

import numpy as np
import librosa
import soundfile as sf
import subprocess
import tempfile
import os
from scipy import signal
from scipy.stats import linregress
import warnings
warnings.filterwarnings('ignore')

class ProfessionalVocalAnalyzer:
    def __init__(self):
        self.target_sr = 16000
        self.chunk_duration = 10  # seconds
        self.num_chunks = 12
        self.top_chunks = 6
        
        # ê¸°ì¤€ê°’ (Z-score ì •ê·œí™”ìš©)
        self.reference_stats = {
            'cpp': {'mean': 9.5, 'std': 2.5},
            'hnr': {'mean': 19.0, 'std': 6.0},
            'spectral_tilt': {'mean': -8.0, 'std': 4.0},
            'spectral_flatness': {'mean': 0.25, 'std': 0.15},
            'f0_confidence': {'mean': 0.65, 'std': 0.2},
            'aperiodicity': {'mean': 0.3, 'std': 0.2}
        }
    
    def convert_m4a_simple(self, m4a_path):
        """ê°„ë‹¨í•œ M4A ë³€í™˜"""
        try:
            temp_wav = tempfile.NamedTemporaryFile(suffix='.wav', delete=False)
            temp_wav_path = temp_wav.name
            temp_wav.close()
            
            cmd = ['ffmpeg', '-i', m4a_path, '-ac', '1', '-ar', '16000', temp_wav_path, '-y']
            result = subprocess.run(cmd, capture_output=True, text=True)
            
            if result.returncode != 0:
                return None
            return temp_wav_path
        except:
            return None
    
    def preprocess_audio(self, audio_file):
        """ì „ì²˜ë¦¬: ëª¨ë…¸, 16kHz, ê°„ë‹¨í•œ ì •ê·œí™”"""
        try:
            print("ğŸ”§ ì „ì²˜ë¦¬ ì¤‘...")
            
            # íŒŒì¼ ë¡œë“œ
            if audio_file.endswith('.m4a'):
                wav_path = self.convert_m4a_simple(audio_file)
                if wav_path:
                    audio, sr = sf.read(wav_path)
                    os.unlink(wav_path)
                else:
                    audio, sr = sf.read(audio_file)
            else:
                audio, sr = sf.read(audio_file)
            
            # ëª¨ë…¸ ë³€í™˜
            if len(audio.shape) > 1:
                audio = np.mean(audio, axis=1)
            
            # 16kHz ë¦¬ìƒ˜í”Œë§
            if sr != self.target_sr:
                audio = librosa.resample(y=audio, orig_sr=sr, target_sr=self.target_sr)
                sr = self.target_sr
            
            # ê°„ë‹¨í•œ ì •ê·œí™” (-23 LUFS ëŒ€ì‹ )
            rms = np.sqrt(np.mean(audio**2))
            if rms > 0:
                audio = audio / (rms * 10)  # ëŒ€ëµì ì¸ ë¼ìš°ë“œë‹ˆìŠ¤ ë§¤ì¹­
            
            print(f"   âœ… ì™„ë£Œ: {len(audio)/sr:.1f}ì´ˆ, {sr}Hz")
            return audio, sr
            
        except Exception as e:
            print(f"   âŒ ì „ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
            return None, None
    
    def energy_zcr_vad(self, audio, sr):
        """Energy+ZCR í•˜ì´ë¸Œë¦¬ë“œ VAD"""
        try:
            frame_length = int(0.02 * sr)  # 20ms
            hop_length = int(0.01 * sr)    # 10ms
            
            # Energy
            energy = []
            for i in range(0, len(audio) - frame_length, hop_length):
                frame = audio[i:i+frame_length]
                energy.append(np.sum(frame**2))
            
            # ZCR
            zcr = []
            for i in range(0, len(audio) - frame_length, hop_length):
                frame = audio[i:i+frame_length]
                zero_crossings = np.sum(np.abs(np.diff(np.sign(frame)))) / 2
                zcr.append(zero_crossings / frame_length)
            
            energy = np.array(energy)
            zcr = np.array(zcr)
            
            # ì„ê³„ê°’
            energy_threshold = np.percentile(energy, 25)
            zcr_threshold = 0.15
            
            # ìœ ì„± íŒì •
            voiced = (energy > energy_threshold) & (zcr < zcr_threshold)
            voiced_ratio = np.mean(voiced)
            
            print(f"   ğŸ“Š ìœ ì„± ë¹„ìœ¨: {voiced_ratio:.1%}")
            
            # ì‹ ë¢°ë„
            confidence = "High" if voiced_ratio >= 0.25 else "Low"
            if voiced_ratio < 0.2:
                print(f"   âš ï¸ ìœ ì„± ë¹„ìœ¨ ë‚®ìŒ - ì‹ ë¢°ë„: {confidence}")
            
            return voiced, voiced_ratio, confidence
            
        except Exception as e:
            print(f"   âŒ VAD ì˜¤ë¥˜: {e}")
            return np.ones(len(audio) // hop_length, dtype=bool), 1.0, "Low"
    
    def extract_representative_chunks(self, audio, sr):
        """ëŒ€í‘œ ìƒ˜í”Œ ì¶”ì¶œ - ê· ë“± ê°„ê²© 12ê°œ â†’ ìƒìœ„ 6ê°œ"""
        try:
            print("ğŸ¯ ëŒ€í‘œ ìƒ˜í”Œ ì¶”ì¶œ ì¤‘...")
            
            total_duration = len(audio) / sr
            chunk_samples = self.chunk_duration * sr
            
            chunks = []
            for i in range(self.num_chunks):
                # ê· ë“± ê°„ê²©
                start_time = i * total_duration / self.num_chunks
                start_sample = int(start_time * sr)
                end_sample = min(start_sample + chunk_samples, len(audio))
                
                if end_sample - start_sample < sr:  # 1ì´ˆ ë¯¸ë§Œ ìŠ¤í‚µ
                    continue
                
                chunk_audio = audio[start_sample:end_sample]
                
                # F0 confidence (ìê¸°ìƒê´€ ê¸°ë°˜)
                f0_conf = self.calculate_f0_confidence_simple(chunk_audio, sr)
                
                # RMS ì •ê·œí™”
                rms_norm = np.sqrt(np.mean(chunk_audio**2))
                
                # ì ìˆ˜ = 0.7Â·F0conf + 0.3Â·RMS
                score = 0.7 * f0_conf + 0.3 * rms_norm
                
                chunks.append({
                    'start_time': start_time,
                    'audio': chunk_audio,
                    'f0_conf': f0_conf,
                    'rms_norm': rms_norm,
                    'score': score
                })
            
            # ìƒìœ„ 6ê°œ ì„ íƒ
            chunks.sort(key=lambda x: x['score'], reverse=True)
            top_chunks = chunks[:self.top_chunks]
            
            print(f"   âœ… {len(chunks)}ê°œ ì¤‘ ìƒìœ„ {len(top_chunks)}ê°œ ì„ íƒ")
            for i, chunk in enumerate(top_chunks[:3]):
                print(f"      #{i+1}: Score={chunk['score']:.3f} (F0={chunk['f0_conf']:.3f}, RMS={chunk['rms_norm']:.3f})")
            
            return top_chunks
            
        except Exception as e:
            print(f"   âŒ ì²­í¬ ì¶”ì¶œ ì˜¤ë¥˜: {e}")
            return []
    
    def calculate_f0_confidence_simple(self, audio, sr):
        """ê°„ë‹¨í•œ F0 confidence (ìê¸°ìƒê´€)"""
        try:
            # ìê¸°ìƒê´€
            autocorr = np.correlate(audio, audio, mode='full')
            autocorr = autocorr[len(autocorr)//2:]
            
            # ì •ê·œí™”
            if autocorr[0] > 0:
                autocorr = autocorr / autocorr[0]
            else:
                return 0.3
            
            # í”¼ì¹˜ ë²”ìœ„ (50-500Hz)
            min_period = sr // 500
            max_period = sr // 50
            
            if max_period >= len(autocorr):
                max_period = len(autocorr) - 1
            
            if min_period >= max_period:
                return 0.3
            
            # ìµœëŒ€ í”¼í¬
            search_range = autocorr[min_period:max_period]
            if len(search_range) == 0:
                return 0.3
            
            max_corr = np.max(search_range)
            return max(0.1, min(1.0, max_corr))
            
        except:
            return 0.3
    
    def extract_light_features(self, chunk_audio, sr):
        """ë¼ì´íŠ¸ íŠ¹ì§• ì„¸íŠ¸ ì¶”ì¶œ"""
        try:
            features = {}
            
            # 1. CPP (ê°„ì´ ë²„ì „ - ì¼‘ìŠ¤íŠ¸ëŸ¼ í”¼í¬)
            features['cpp'] = self.calculate_cpp_light(chunk_audio, sr)
            
            # 2. HNR (ìê¸°ìƒê´€ ê¸°ë°˜)
            features['hnr'] = self.calculate_hnr_autocorr(chunk_audio, sr)
            
            # 3. Spectral Tilt (300Hz-3kHz ì„ í˜•íšŒê·€)
            features['spectral_tilt'] = self.calculate_spectral_tilt(chunk_audio, sr)
            
            # 4. Spectral Flatness
            features['spectral_flatness'] = self.calculate_spectral_flatness(chunk_audio, sr)
            
            # 5. F0 confidence
            features['f0_confidence'] = self.calculate_f0_confidence_simple(chunk_audio, sr)
            
            # 6. Aperiodicity proxy (ê°„ë‹¨í•œ ë³€ë™ì„±)
            features['aperiodicity'] = self.calculate_aperiodicity_proxy(chunk_audio, sr)
            
            # ë³´ì¡°: Spectral centroid, rolloff
            features['spectral_centroid'] = self.calculate_spectral_centroid(chunk_audio, sr)
            features['spectral_rolloff'] = self.calculate_spectral_rolloff(chunk_audio, sr)
            
            return features
            
        except Exception as e:
            print(f"   âŒ íŠ¹ì§• ì¶”ì¶œ ì˜¤ë¥˜: {e}")
            return {}
    
    def calculate_cpp_light(self, audio, sr):
        """ê°„ì´ CPP - ì¼‘ìŠ¤íŠ¸ëŸ¼ í”¼í¬ prominence"""
        try:
            # 40ms ìœˆë„ìš°
            frame_length = int(0.04 * sr)
            if len(audio) < frame_length:
                return 6.0
            
            # ìœˆë„ì‰
            windowed = audio[:frame_length] * np.hanning(frame_length)
            
            # FFT â†’ ë¡œê·¸ ìŠ¤í™íŠ¸ëŸ¼ â†’ ì¼‘ìŠ¤íŠ¸ëŸ¼
            fft = np.fft.fft(windowed)
            log_spectrum = np.log(np.abs(fft) + 1e-10)
            cepstrum = np.fft.ifft(log_spectrum).real
            
            # í”¼ì¹˜ ë²”ìœ„ (2-20ms quefrency, 50-500Hz)
            min_q = int(sr * 0.002)  # 2ms
            max_q = int(sr * 0.02)   # 20ms
            
            if max_q >= len(cepstrum):
                max_q = len(cepstrum) - 1
            
            if min_q >= max_q:
                return 6.0
            
            pitch_cepstrum = cepstrum[min_q:max_q]
            
            # ìµœëŒ€ í”¼í¬ì™€ ì£¼ë³€ í‰ê· ì˜ ì°¨ì´
            max_peak = np.max(pitch_cepstrum)
            mean_level = np.mean(pitch_cepstrum)
            
            cpp = (max_peak - mean_level) * 1000  # dB ìŠ¤ì¼€ì¼
            return max(0, min(20, cpp))
            
        except:
            return 6.0
    
    def calculate_hnr_autocorr(self, audio, sr):
        """ìê¸°ìƒê´€ ê¸°ë°˜ HNR"""
        try:
            # ìê¸°ìƒê´€
            autocorr = np.correlate(audio, audio, mode='full')
            autocorr = autocorr[len(autocorr)//2:]
            
            if len(autocorr) < 2 or autocorr[0] <= 0:
                return 12.0
            
            # ì •ê·œí™”
            autocorr = autocorr / autocorr[0]
            
            # í”¼ì¹˜ ë²”ìœ„ì—ì„œ ìµœëŒ€ í”¼í¬
            min_period = sr // 400  # 400Hz
            max_period = sr // 80   # 80Hz
            
            if max_period >= len(autocorr):
                max_period = len(autocorr) - 1
            
            if min_period >= max_period:
                return 12.0
            
            search_range = autocorr[min_period:max_period]
            if len(search_range) == 0:
                return 12.0
            
            max_corr = np.max(search_range)
            noise_level = 1 - max_corr
            
            if noise_level <= 0.01:
                return 25.0
            
            hnr = 10 * np.log10(max_corr / noise_level)
            return max(0, min(30, hnr))
            
        except:
            return 12.0
    
    def calculate_spectral_tilt(self, audio, sr):
        """300Hz-3kHz ì§ì„  íšŒê·€ ê¸°ìš¸ê¸°"""
        try:
            # FFT
            fft = np.fft.rfft(audio)
            freqs = np.fft.rfftfreq(len(audio), 1/sr)
            magnitude = np.abs(fft) + 1e-10
            
            # 300-3000Hz ë²”ìœ„
            mask = (freqs >= 300) & (freqs <= 3000)
            
            if np.sum(mask) < 10:
                return -6.0
            
            freq_range = freqs[mask]
            mag_range = magnitude[mask]
            
            # ë¡œê·¸ ìŠ¤ì¼€ì¼ ì„ í˜• íšŒê·€
            log_mag = 20 * np.log10(mag_range)
            log_freq = np.log10(freq_range)
            
            slope, _, _, _, _ = linregress(log_freq, log_mag)
            
            # dB/octave ë³€í™˜
            db_per_octave = slope * np.log10(2)
            
            return max(-20, min(5, db_per_octave))
            
        except:
            return -6.0
    
    def calculate_spectral_flatness(self, audio, sr):
        """Spectral Flatness (geometric/arithmetic mean)"""
        try:
            fft = np.fft.rfft(audio)
            magnitude = np.abs(fft) + 1e-10
            
            # Geometric mean / Arithmetic mean
            geometric_mean = np.exp(np.mean(np.log(magnitude)))
            arithmetic_mean = np.mean(magnitude)
            
            flatness = geometric_mean / arithmetic_mean
            return min(1.0, max(0.0, flatness))
            
        except:
            return 0.3
    
    def calculate_aperiodicity_proxy(self, audio, sr):
        """ë¹„ì£¼ê¸°ì„± ëŒ€ë¦¬ ì§€í‘œ (RMS ë³€ë™ì„±)"""
        try:
            frame_length = int(0.01 * sr)  # 10ms í”„ë ˆì„
            
            if len(audio) < frame_length * 3:
                return 0.2
            
            # í”„ë ˆì„ë³„ RMS
            rms_values = []
            for i in range(0, len(audio) - frame_length, frame_length):
                frame = audio[i:i+frame_length]
                rms = np.sqrt(np.mean(frame**2))
                rms_values.append(rms)
            
            if len(rms_values) < 2:
                return 0.2
            
            # ë³€ë™ ê³„ìˆ˜ (coefficient of variation)
            mean_rms = np.mean(rms_values)
            std_rms = np.std(rms_values)
            
            if mean_rms > 0:
                cv = std_rms / mean_rms
                return min(1.0, max(0.0, cv))
            else:
                return 0.2
            
        except:
            return 0.2
    
    def calculate_spectral_centroid(self, audio, sr):
        """Spectral Centroid"""
        try:
            centroid = librosa.feature.spectral_centroid(y=audio, sr=sr)[0]
            return np.mean(centroid)
        except:
            return 1500.0
    
    def calculate_spectral_rolloff(self, audio, sr):
        """Spectral Rolloff (85%)"""
        try:
            rolloff = librosa.feature.spectral_rolloff(y=audio, sr=sr, roll_percent=0.85)[0]
            return np.mean(rolloff)
        except:
            return 3500.0
    
    def aggregate_features(self, all_features):
        """íŠ¹ì§• ì§‘ê³„ - mean, p90, IQR"""
        try:
            print("ğŸ“Š íŠ¹ì§• ì§‘ê³„ ì¤‘...")
            
            aggregated = {}
            feature_names = ['cpp', 'hnr', 'spectral_tilt', 'spectral_flatness', 
                           'f0_confidence', 'aperiodicity', 'spectral_centroid', 'spectral_rolloff']
            
            for name in feature_names:
                values = [f.get(name, 0) for f in all_features if name in f and not np.isnan(f.get(name, 0))]
                
                if values:
                    aggregated[f'{name}_mean'] = np.mean(values)
                    aggregated[f'{name}_p90'] = np.percentile(values, 90)
                    aggregated[f'{name}_iqr'] = np.percentile(values, 75) - np.percentile(values, 25)
                else:
                    # ê¸°ë³¸ê°’
                    defaults = {'cpp': 7, 'hnr': 15, 'spectral_tilt': -8, 'spectral_flatness': 0.3,
                              'f0_confidence': 0.5, 'aperiodicity': 0.3, 'spectral_centroid': 1500, 'spectral_rolloff': 3500}
                    default_val = defaults.get(name, 0)
                    aggregated[f'{name}_mean'] = default_val
                    aggregated[f'{name}_p90'] = default_val
                    aggregated[f'{name}_iqr'] = 0
            
            print(f"   âœ… {len(feature_names)}ê°œ íŠ¹ì§• ì§‘ê³„ ì™„ë£Œ")
            return aggregated
            
        except Exception as e:
            print(f"   âŒ íŠ¹ì§• ì§‘ê³„ ì˜¤ë¥˜: {e}")
            return {}
    
    def apply_source_correction(self, features, source_hint="unknown"):
        """ì†ŒìŠ¤ ë³´ì • í…Œì´ë¸” ì ìš©"""
        try:
            print(f"ğŸ”§ ì†ŒìŠ¤ ë³´ì • ì ìš©: {source_hint}")
            
            # ë³´ì • í…Œì´ë¸”
            corrections = {
                "kakaotalk": {
                    "hnr_mean": -1.0,
                    "spectral_tilt_mean": +0.5,
                    "spectral_flatness_mean": +0.02
                },
                "instagram": {
                    "cpp_mean": -0.8
                },
                "low_quality": {
                    "hnr_mean": -2.0,
                    "spectral_flatness_mean": +0.05
                }
            }
            
            if source_hint in corrections:
                correction_table = corrections[source_hint]
                applied = 0
                for key, correction in correction_table.items():
                    if key in features:
                        old_value = features[key]
                        features[key] += correction
                        print(f"   {key}: {old_value:.2f} â†’ {features[key]:.2f} ({correction:+.2f})")
                        applied += 1
                
                if applied == 0:
                    print("   ë³´ì • ì ìš©ëœ í•­ëª© ì—†ìŒ")
            else:
                print("   ì•Œë ¤ì§„ ì†ŒìŠ¤ ì•„ë‹˜ - ë³´ì • ìƒëµ")
            
            return features
            
        except Exception as e:
            print(f"   âŒ ì†ŒìŠ¤ ë³´ì • ì˜¤ë¥˜: {e}")
            return features
    
    def calculate_final_clarity_score(self, features):
        """ìµœì¢… ì„ ëª…ë„ ì ìˆ˜ ê³„ì‚°"""
        try:
            print("ğŸ¯ ìµœì¢… ì ìˆ˜ ê³„ì‚° ì¤‘...")
            
            # Z-score ì •ê·œí™”
            z_scores = {}
            core_features = ['cpp', 'hnr', 'spectral_tilt', 'spectral_flatness', 'f0_confidence', 'aperiodicity']
            
            for feature in core_features:
                mean_key = f'{feature}_mean'
                if mean_key in features:
                    ref = self.reference_stats[feature]
                    z_scores[feature] = (features[mean_key] - ref['mean']) / ref['std']
                else:
                    z_scores[feature] = 0
            
            # ì„ ëª…ë„ ê³µì‹
            clarity_z = (z_scores['cpp'] + 
                        z_scores['hnr'] - 
                        z_scores['spectral_tilt'] - 
                        z_scores['spectral_flatness'] + 
                        0.5 * z_scores['f0_confidence'] - 
                        0.5 * z_scores['aperiodicity'])
            
            # 0-100 ì„ í˜• ë§¤í•‘ (z-score -3~+3ì„ 0~100ìœ¼ë¡œ)
            clarity_score = np.clip((clarity_z + 3) * 100 / 6, 0, 100)
            
            # ê°€ì„±/ìˆ¨ì„ì„ í•˜ë“œìº¡
            hnr_mean = features.get('hnr_mean', 15)
            if hnr_mean < 10:
                clarity_score = min(clarity_score, 60)
                print("   âš ï¸ ë‚®ì€ HNR - ì„ ëª…ë„ ìºí•‘ ì ìš© (60 ì´í•˜)")
            
            # ë“±ê¸‰í™”
            if clarity_score >= 70:
                grade = "High"
            elif clarity_score >= 40:
                grade = "Medium"
            else:
                grade = "Low"
            
            # ë³´ì¡° íƒœê·¸
            tilt_mean = features.get('spectral_tilt_mean', -8)
            centroid_mean = features.get('spectral_centroid_mean', 1500)
            
            brightness = "ë°ìŒ" if (tilt_mean > -6 and centroid_mean > 1800) else "ì–´ë‘ì›€"
            
            aperiodicity_mean = features.get('aperiodicity_mean', 0.3)
            roughness = "ê±°ë¦¼" if (aperiodicity_mean > 0.4 or hnr_mean < 12) else "ë¶€ë“œëŸ¬ì›€"
            
            results = {
                'clarity_score': clarity_score,
                'clarity_grade': grade,
                'brightness_tag': brightness,
                'roughness_tag': roughness,
                'z_scores': z_scores,
                'core_features': {k: features.get(f'{k}_mean', 0) for k in core_features}
            }
            
            print(f"   âœ… ì„ ëª…ë„: {clarity_score:.1f} ({grade})")
            print(f"   ğŸ·ï¸ íƒœê·¸: {brightness}, {roughness}")
            print(f"   ğŸ“Š ì£¼ìš” íŠ¹ì§•: CPP={results['core_features']['cpp']:.1f}, HNR={results['core_features']['hnr']:.1f}")
            
            return results
            
        except Exception as e:
            print(f"   âŒ ìµœì¢… ì ìˆ˜ ê³„ì‚° ì˜¤ë¥˜: {e}")
            return {}
    
    def analyze_vocal_file(self, audio_file, source_hint="unknown"):
        """ë©”ì¸ ë¶„ì„ í•¨ìˆ˜"""
        print("=" * 70)
        print("ğŸ¤ ì „ë¬¸ ë³´ì»¬ ë¶„ì„ê¸° - ì „ì—­ í’ˆì§ˆ ë¶„ì„")
        print("=" * 70)
        filename = audio_file.split('/')[-1].split('\\')[-1]
        print(f"ğŸ“ íŒŒì¼: {filename}")
        
        # 1. ì „ì²˜ë¦¬
        audio, sr = self.preprocess_audio(audio_file)
        if audio is None:
            print("âŒ ì „ì²˜ë¦¬ ì‹¤íŒ¨")
            return None
        
        # 2. VAD
        voiced_frames, voiced_ratio, vad_confidence = self.energy_zcr_vad(audio, sr)
        
        # 3. ëŒ€í‘œ ìƒ˜í”Œ ì¶”ì¶œ
        chunks = self.extract_representative_chunks(audio, sr)
        if not chunks:
            print("âŒ ëŒ€í‘œ ìƒ˜í”Œ ì¶”ì¶œ ì‹¤íŒ¨")
            return None
        
        # 4. ë¼ì´íŠ¸ íŠ¹ì§• ì¶”ì¶œ
        print("ğŸ” ë¼ì´íŠ¸ íŠ¹ì§• ì¶”ì¶œ ì¤‘...")
        all_features = []
        for i, chunk in enumerate(chunks):
            features = self.extract_light_features(chunk['audio'], sr)
            if features:
                all_features.append(features)
        
        if not all_features:
            print("âŒ íŠ¹ì§• ì¶”ì¶œ ì‹¤íŒ¨")
            return None
        
        print(f"   âœ… {len(all_features)}ê°œ ì²­í¬ì—ì„œ íŠ¹ì§• ì¶”ì¶œ ì™„ë£Œ")
        
        # 5. íŠ¹ì§• ì§‘ê³„
        aggregated_features = self.aggregate_features(all_features)
        if not aggregated_features:
            print("âŒ íŠ¹ì§• ì§‘ê³„ ì‹¤íŒ¨")
            return None
        
        # 6. ì†ŒìŠ¤ ë³´ì •
        corrected_features = self.apply_source_correction(aggregated_features, source_hint)
        
        # 7. ìµœì¢… ìŠ¤ì½”ì–´ë§
        results = self.calculate_final_clarity_score(corrected_features)
        if not results:
            print("âŒ ìµœì¢… ì ìˆ˜ ê³„ì‚° ì‹¤íŒ¨")
            return None
        
        # ì‹ ë¢°ë„ ì •ë³´ ì¶”ê°€
        results['confidence_info'] = {
            'vad_confidence': vad_confidence,
            'voiced_ratio': voiced_ratio,
            'num_chunks_used': len(chunks),
            'audio_duration': len(audio) / sr
        }
        
        return results

def test_professional_analyzer():
    """ì „ë¬¸ ë¶„ì„ê¸° í…ŒìŠ¤íŠ¸"""
    
    analyzer = ProfessionalVocalAnalyzer()
    
    # í…ŒìŠ¤íŠ¸ íŒŒì¼ë“¤
    test_files = [
        (r"C:\Users\user\Desktop\vocals_extracted\ê¹€ë²”ìˆ˜_ê¹€ë²”ìˆ˜ - Dear Love_ë³´ì»¬.wav", "unknown"),
        (r"C:\Users\user\Documents\ì¹´ì¹´ì˜¤í†¡ ë°›ì€ íŒŒì¼\kakaotalk_1756474302376.m4a", "kakaotalk"),
        (r"C:\Users\user\Desktop\vocals_extracted\ë¡œì´í‚´_ë¡œì´í‚´ - As Is_ë³´ì»¬.wav", "unknown"),
        (r"C:\Users\user\Documents\ì†Œë¦¬ ë…¹ìŒ\ê°€ì„±_ê°€ì„±ë¹„ë¸Œë¼í† .wav", "unknown")
    ]
    
    results_summary = []
    
    for audio_file, source_hint in test_files:
        result = analyzer.analyze_vocal_file(audio_file, source_hint)
        
        if result:
            filename = audio_file.split('/')[-1].split('\\')[-1]
            results_summary.append({
                'file': filename[:25],
                'clarity_score': result['clarity_score'],
                'grade': result['clarity_grade'],
                'brightness': result['brightness_tag'],
                'roughness': result['roughness_tag'],
                'confidence': result['confidence_info']['vad_confidence'],
                'voiced_ratio': result['confidence_info']['voiced_ratio']
            })
            print("âœ… ë¶„ì„ ì™„ë£Œ!")
        else:
            print("âŒ ë¶„ì„ ì‹¤íŒ¨!")
        print()
    
    # ìµœì¢… ë¹„êµ
    if results_summary:
        print("=" * 80)
        print("ğŸ† ìµœì¢… ë¹„êµ ê²°ê³¼")
        print("=" * 80)
        
        print(f"\n{'íŒŒì¼':<27} | {'ì„ ëª…ë„':<6} | {'ë“±ê¸‰':<6} | {'ë°ê¸°':<6} | {'ê±°ì¹¨':<8} | {'ì‹ ë¢°ë„':<6} | ìœ ì„±%")
        print("-" * 85)
        
        for r in results_summary:
            print(f"{r['file']:<27} | {r['clarity_score']:<6.1f} | {r['grade']:<6} | {r['brightness']:<6} | {r['roughness']:<8} | {r['confidence']:<6} | {r['voiced_ratio']:<5.1%}")
        
        print(f"\nğŸ’¡ ì˜ˆìƒ ìˆœì„œ: ê¹€ë²”ìˆ˜ > kakaotalk > ë¡œì´í‚´ > ê°€ì„±")
        sorted_results = sorted(results_summary, key=lambda x: x['clarity_score'], reverse=True)
        actual_order = " > ".join([r['file'].split('_')[0][:8] for r in sorted_results])
        print(f"ğŸ’¡ ì‹¤ì œ ìˆœì„œ: {actual_order}")

if __name__ == "__main__":
    test_professional_analyzer()