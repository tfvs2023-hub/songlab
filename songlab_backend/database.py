"""
SongLab ì‚¬ìš©ì ë¶„ì„ ë°ì´í„° ì €ì¥ ì‹œìŠ¤í…œ
SQLite ê¸°ë°˜ ë¡œì»¬ ë°ì´í„°ë² ì´ìŠ¤
"""

import sqlite3
import json
from datetime import datetime
from typing import Dict, List, Optional
import hashlib
import os

class SongLabDB:
    def __init__(self, db_path: str = "songlab_data.db"):
        self.db_path = db_path
        self.init_database()
    
    def init_database(self):
        """ë°ì´í„°ë² ì´ìŠ¤ í…Œì´ë¸” ì´ˆê¸°í™”"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # ì‚¬ìš©ì ë¶„ì„ ê²°ê³¼ í…Œì´ë¸”
        cursor.execute('''
        CREATE TABLE IF NOT EXISTS user_analyses (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            session_id TEXT NOT NULL,
            file_name TEXT,
            file_hash TEXT,
            upload_time TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            
            -- MBTI ê²°ê³¼
            mbti_type_code TEXT,
            mbti_type_name TEXT,
            brightness_score INTEGER,
            thickness_score INTEGER,
            clarity_score INTEGER,
            power_score INTEGER,
            
            -- ìŒì—­ ì •ë³´
            current_note TEXT,
            potential_note TEXT,
            
            -- ë©”íƒ€ë°ì´í„°
            file_size INTEGER,
            duration_seconds REAL,
            analysis_duration_ms INTEGER,
            user_ip TEXT,
            user_agent TEXT
        )
        ''')
        
        # ì§‘ê³„ í†µê³„ í…Œì´ë¸”
        cursor.execute('''
        CREATE TABLE IF NOT EXISTS daily_stats (
            date TEXT PRIMARY KEY,
            total_analyses INTEGER DEFAULT 0,
            unique_users INTEGER DEFAULT 0,
            avg_analysis_time REAL DEFAULT 0,
            most_common_type TEXT
        )
        ''')
        
        # ì¸ë±ìŠ¤ ìƒì„±
        cursor.execute('CREATE INDEX IF NOT EXISTS idx_upload_time ON user_analyses(upload_time)')
        cursor.execute('CREATE INDEX IF NOT EXISTS idx_mbti_type ON user_analyses(mbti_type_code)')
        cursor.execute('CREATE INDEX IF NOT EXISTS idx_session ON user_analyses(session_id)')
        
        conn.commit()
        conn.close()
        
        print(f"âœ… ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ: {self.db_path}")
    
    def generate_file_hash(self, file_content: bytes) -> str:
        """íŒŒì¼ í•´ì‹œ ìƒì„± (ì¤‘ë³µ ê°ì§€ìš©)"""
        return hashlib.md5(file_content).hexdigest()
    
    def save_analysis(self, analysis_data: Dict) -> int:
        """ë¶„ì„ ê²°ê³¼ ì €ì¥"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # ë¶„ì„ ë°ì´í„° íŒŒì‹±
        mbti = analysis_data.get('mbti', {})
        scores = mbti.get('scores', {})
        
        cursor.execute('''
        INSERT INTO user_analyses (
            session_id, file_name, file_hash, 
            mbti_type_code, mbti_type_name,
            brightness_score, thickness_score, clarity_score, power_score,
            current_note, potential_note,
            file_size, duration_seconds, analysis_duration_ms,
            user_ip, user_agent
        ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
        ''', (
            analysis_data.get('session_id'),
            analysis_data.get('file_name'),
            analysis_data.get('file_hash'),
            analysis_data.get('mbti_type_code'),
            mbti.get('typeName'),
            scores.get('brightness', 0),
            scores.get('thickness', 0),
            scores.get('clarity', 0),
            scores.get('power', 0),
            mbti.get('currentNote'),
            mbti.get('potentialNote'),
            analysis_data.get('file_size', 0),
            analysis_data.get('duration_seconds', 0),
            analysis_data.get('analysis_duration_ms', 0),
            analysis_data.get('user_ip'),
            analysis_data.get('user_agent')
        ))
        
        analysis_id = cursor.lastrowid
        conn.commit()
        conn.close()
        
        # ì¼ë³„ í†µê³„ ì—…ë°ì´íŠ¸
        self.update_daily_stats()
        
        return analysis_id
    
    def update_daily_stats(self):
        """ì¼ë³„ í†µê³„ ì—…ë°ì´íŠ¸"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        today = datetime.now().strftime('%Y-%m-%d')
        
        # ì˜¤ëŠ˜ì˜ í†µê³„ ê³„ì‚°
        cursor.execute('''
        SELECT 
            COUNT(*) as total,
            COUNT(DISTINCT session_id) as unique_users,
            AVG(analysis_duration_ms) as avg_time,
            mbti_type_code,
            COUNT(mbti_type_code) as type_count
        FROM user_analyses 
        WHERE DATE(upload_time) = ?
        GROUP BY mbti_type_code
        ORDER BY type_count DESC
        LIMIT 1
        ''', (today,))
        
        result = cursor.fetchone()
        if result:
            total, unique_users, avg_time, most_common_type, _ = result
            
            cursor.execute('''
            INSERT OR REPLACE INTO daily_stats 
            (date, total_analyses, unique_users, avg_analysis_time, most_common_type)
            VALUES (?, ?, ?, ?, ?)
            ''', (today, total, unique_users, avg_time or 0, most_common_type))
        
        conn.commit()
        conn.close()
    
    def get_statistics(self) -> Dict:
        """ì „ì²´ í†µê³„ ì¡°íšŒ"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # ê¸°ë³¸ í†µê³„
        cursor.execute('SELECT COUNT(*) FROM user_analyses')
        total_analyses = cursor.fetchone()[0]
        
        cursor.execute('SELECT COUNT(DISTINCT session_id) FROM user_analyses')
        unique_users = cursor.fetchone()[0]
        
        # MBTI íƒ€ì… ë¶„í¬
        cursor.execute('''
        SELECT mbti_type_code, mbti_type_name, COUNT(*) as count
        FROM user_analyses 
        WHERE mbti_type_code IS NOT NULL
        GROUP BY mbti_type_code, mbti_type_name
        ORDER BY count DESC
        ''')
        mbti_distribution = [
            {'type': row[0], 'name': row[1], 'count': row[2]} 
            for row in cursor.fetchall()
        ]
        
        # í‰ê·  ì ìˆ˜
        cursor.execute('''
        SELECT 
            AVG(brightness_score) as avg_brightness,
            AVG(thickness_score) as avg_thickness,
            AVG(clarity_score) as avg_clarity,
            AVG(power_score) as avg_power
        FROM user_analyses
        ''')
        avg_scores = cursor.fetchone()
        
        # ìµœê·¼ 7ì¼ íŠ¸ë Œë“œ
        cursor.execute('''
        SELECT DATE(upload_time) as date, COUNT(*) as count
        FROM user_analyses 
        WHERE upload_time >= datetime('now', '-7 days')
        GROUP BY DATE(upload_time)
        ORDER BY date
        ''')
        weekly_trend = [{'date': row[0], 'count': row[1]} for row in cursor.fetchall()]
        
        conn.close()
        
        return {
            'total_analyses': total_analyses,
            'unique_users': unique_users,
            'mbti_distribution': mbti_distribution,
            'average_scores': {
                'brightness': round(avg_scores[0] or 0, 1),
                'thickness': round(avg_scores[1] or 0, 1),
                'clarity': round(avg_scores[2] or 0, 1),
                'power': round(avg_scores[3] or 0, 1)
            },
            'weekly_trend': weekly_trend
        }
    
    def export_data(self, output_file: str = None) -> str:
        """ë°ì´í„° ë‚´ë³´ë‚´ê¸° (CSV)"""
        if not output_file:
            output_file = f"songlab_export_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv"
        
        conn = sqlite3.connect(self.db_path)
        
        # CSV ë‚´ë³´ë‚´ê¸°
        import pandas as pd
        df = pd.read_sql_query('''
        SELECT 
            upload_time,
            mbti_type_code,
            mbti_type_name,
            brightness_score,
            thickness_score,
            clarity_score,
            power_score,
            current_note,
            potential_note,
            file_size,
            duration_seconds
        FROM user_analyses
        ORDER BY upload_time DESC
        ''', conn)
        
        df.to_csv(output_file, index=False, encoding='utf-8-sig')
        conn.close()
        
        return output_file
    
    def cleanup_old_data(self, days_to_keep: int = 90):
        """ì˜¤ë˜ëœ ë°ì´í„° ì •ë¦¬"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute('''
        DELETE FROM user_analyses 
        WHERE upload_time < datetime('now', '-{} days')
        '''.format(days_to_keep))
        
        deleted_count = cursor.rowcount
        conn.commit()
        conn.close()
        
        print(f"ğŸ§¹ {deleted_count}ê°œì˜ ì˜¤ë˜ëœ ë ˆì½”ë“œ ì‚­ì œë¨")
        return deleted_count


# FastAPIì— í†µí•©í•  í•¨ìˆ˜ë“¤
def init_database():
    """ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” (FastAPI ì‹œì‘ì‹œ í˜¸ì¶œ)"""
    db = SongLabDB()
    return db

def save_user_analysis(db: SongLabDB, result: Dict, metadata: Dict) -> int:
    """ì‚¬ìš©ì ë¶„ì„ ê²°ê³¼ ì €ì¥"""
    analysis_data = {
        'session_id': metadata.get('session_id'),
        'file_name': metadata.get('file_name'),
        'file_hash': metadata.get('file_hash'),
        'mbti_type_code': get_mbti_type_code(result.get('mbti', {})),
        'file_size': metadata.get('file_size', 0),
        'duration_seconds': metadata.get('duration_seconds', 0),
        'analysis_duration_ms': metadata.get('analysis_duration_ms', 0),
        'user_ip': metadata.get('user_ip'),
        'user_agent': metadata.get('user_agent'),
        'mbti': result.get('mbti', {})
    }
    
    return db.save_analysis(analysis_data)

def get_mbti_type_code(mbti_data: Dict) -> str:
    """MBTI ë°ì´í„°ì—ì„œ íƒ€ì… ì½”ë“œ ì¶”ì¶œ"""
    scores = mbti_data.get('scores', {})
    type_code = ''
    type_code += 'D' if scores.get('brightness', 0) < 0 else 'B'
    type_code += 'K' if scores.get('thickness', 0) > 0 else 'N'
    type_code += 'C' if scores.get('clarity', 0) > 0 else 'R'
    type_code += 'S' if scores.get('power', 0) > 0 else 'W'
    return type_code


if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸
    db = SongLabDB()
    
    # ìƒ˜í”Œ ë°ì´í„° ìƒì„±
    sample_result = {
        'mbti': {
            'typeName': 'ì¹´ë¦¬ìŠ¤ë§ˆí‹± ë³´ì»¬',
            'scores': {'brightness': -65, 'thickness': 75, 'clarity': 45, 'power': 82},
            'currentNote': '3ì˜¥íƒ€ë¸Œ íŒŒ#',
            'potentialNote': '4ì˜¥íƒ€ë¸Œ ë¼'
        }
    }
    
    sample_metadata = {
        'session_id': 'test_session_123',
        'file_name': 'test_voice.wav',
        'file_hash': 'abc123def456',
        'file_size': 1024000,
        'duration_seconds': 15.3,
        'analysis_duration_ms': 5000,
        'user_ip': '127.0.0.1',
        'user_agent': 'TestBrowser/1.0'
    }
    
    # ë°ì´í„° ì €ì¥ í…ŒìŠ¤íŠ¸
    analysis_id = save_user_analysis(db, sample_result, sample_metadata)
    print(f"ğŸ“ ë¶„ì„ ì €ì¥ ì™„ë£Œ (ID: {analysis_id})")
    
    # í†µê³„ ì¡°íšŒ
    stats = db.get_statistics()
    print(f"ğŸ“Š ì´ ë¶„ì„: {stats['total_analyses']}ê±´")
    print(f"ğŸ‘¥ ì‚¬ìš©ì: {stats['unique_users']}ëª…")