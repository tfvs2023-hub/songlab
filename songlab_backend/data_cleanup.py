"""
ë°ì´í„° ì •ë¦¬ ë° ë¹„ìš© ìµœì í™” ì‹œìŠ¤í…œ
ì˜¤ë˜ëœ ë°ì´í„° ì‚­ì œ, ì••ì¶•, ë°±ì—… ê´€ë¦¬
"""

import sqlite3
import os
import gzip
import json
from datetime import datetime, timedelta
from database import SongLabDB

class DataManager:
    def __init__(self, db_path="songlab_data.db"):
        self.db = SongLabDB(db_path)
        self.db_path = db_path
    
    def optimize_storage(self):
        """ìŠ¤í† ë¦¬ì§€ ìµœì í™”"""
        print("ğŸ“Š ë°ì´í„° ìµœì í™” ì‹œì‘...")
        
        # 1. ì˜¤ë˜ëœ ìƒì„¸ ë°ì´í„° ì‚­ì œ (3ê°œì›”)
        deleted = self.cleanup_old_data(days=90)
        
        # 2. ì¤‘ë³µ ë°ì´í„° ì œê±°
        duplicates = self.remove_duplicates()
        
        # 3. ë°ì´í„°ë² ì´ìŠ¤ VACUUM (ë¹ˆ ê³µê°„ ì •ë¦¬)
        self.vacuum_database()
        
        # 4. íŒŒì¼ í¬ê¸° í™•ì¸
        file_size = self.get_db_size()
        
        print(f"âœ… ìµœì í™” ì™„ë£Œ:")
        print(f"   ì‚­ì œëœ ë ˆì½”ë“œ: {deleted}ê°œ")
        print(f"   ì¤‘ë³µ ì œê±°: {duplicates}ê°œ")
        print(f"   í˜„ì¬ DB í¬ê¸°: {file_size:.2f}MB")
        
        return {
            'deleted_records': deleted,
            'removed_duplicates': duplicates,
            'db_size_mb': file_size
        }
    
    def cleanup_old_data(self, days=90):
        """ì˜¤ë˜ëœ ë°ì´í„° ì‚­ì œ"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # 3ê°œì›” ì´ìƒ ëœ ë°ì´í„° ì‚­ì œ
        cursor.execute('''
        DELETE FROM user_analyses 
        WHERE upload_time < datetime('now', '-{} days')
        '''.format(days))
        
        deleted_count = cursor.rowcount
        conn.commit()
        conn.close()
        
        return deleted_count
    
    def remove_duplicates(self):
        """ì¤‘ë³µ ë°ì´í„° ì œê±° (ê°™ì€ íŒŒì¼ í•´ì‹œ)"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # ì¤‘ë³µ ì œê±° (ìµœì‹  ê²ƒë§Œ ìœ ì§€)
        cursor.execute('''
        DELETE FROM user_analyses 
        WHERE id NOT IN (
            SELECT MAX(id) 
            FROM user_analyses 
            GROUP BY file_hash
        )
        ''')
        
        removed_count = cursor.rowcount
        conn.commit()
        conn.close()
        
        return removed_count
    
    def vacuum_database(self):
        """ë°ì´í„°ë² ì´ìŠ¤ ì••ì¶•"""
        conn = sqlite3.connect(self.db_path)
        conn.execute('VACUUM')
        conn.close()
    
    def get_db_size(self):
        """DB íŒŒì¼ í¬ê¸° (MB)"""
        if os.path.exists(self.db_path):
            return os.path.getsize(self.db_path) / (1024 * 1024)
        return 0
    
    def export_and_compress(self, backup_path="backup"):
        """ë°ì´í„° ì••ì¶• ë°±ì—…"""
        if not os.path.exists(backup_path):
            os.makedirs(backup_path)
        
        # í˜„ì¬ ë‚ ì§œë¡œ ë°±ì—… íŒŒì¼ëª…
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        backup_file = f"{backup_path}/songlab_backup_{timestamp}.json.gz"
        
        # ë°ì´í„° ì¶”ì¶œ
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute('''
        SELECT * FROM user_analyses 
        ORDER BY upload_time DESC
        ''')
        
        # JSONìœ¼ë¡œ ë³€í™˜
        columns = [description[0] for description in cursor.description]
        data = []
        for row in cursor.fetchall():
            data.append(dict(zip(columns, row)))
        
        conn.close()
        
        # ì••ì¶• ì €ì¥
        with gzip.open(backup_file, 'wt', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, default=str)
        
        # ì••ì¶•ë¥  ê³„ì‚°
        original_size = self.get_db_size()
        compressed_size = os.path.getsize(backup_file) / (1024 * 1024)
        compression_ratio = (1 - compressed_size / original_size) * 100 if original_size > 0 else 0
        
        print(f"ğŸ“¦ ë°±ì—… ì™„ë£Œ: {backup_file}")
        print(f"   ì›ë³¸: {original_size:.2f}MB â†’ ì••ì¶•: {compressed_size:.2f}MB")
        print(f"   ì••ì¶•ë¥ : {compression_ratio:.1f}%")
        
        return backup_file
    
    def get_storage_stats(self):
        """ìŠ¤í† ë¦¬ì§€ í†µê³„"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # ì „ì²´ ë ˆì½”ë“œ ìˆ˜
        cursor.execute('SELECT COUNT(*) FROM user_analyses')
        total_records = cursor.fetchone()[0]
        
        # ì›”ë³„ ë°ì´í„°ëŸ‰
        cursor.execute('''
        SELECT 
            strftime('%Y-%m', upload_time) as month,
            COUNT(*) as count,
            AVG(file_size) as avg_file_size
        FROM user_analyses 
        GROUP BY strftime('%Y-%m', upload_time)
        ORDER BY month DESC
        LIMIT 12
        ''')
        
        monthly_data = cursor.fetchall()
        
        # ì˜ˆìƒ ì›” ì¦ê°€ëŸ‰
        if len(monthly_data) >= 2:
            recent_avg = (monthly_data[0][1] + monthly_data[1][1]) / 2
        else:
            recent_avg = monthly_data[0][1] if monthly_data else 0
        
        conn.close()
        
        # í˜„ì¬ í¬ê¸° ë° ì˜ˆìƒ ì¦ê°€ëŸ‰
        current_size = self.get_db_size()
        estimated_monthly_growth = (recent_avg * 0.05)  # ë ˆì½”ë“œë‹¹ ì•½ 50KB
        
        return {
            'total_records': total_records,
            'current_db_size_mb': current_size,
            'estimated_monthly_growth_mb': estimated_monthly_growth,
            'estimated_yearly_cost_usd': estimated_monthly_growth * 12 * 0.10 / 1024,  # AWS EBS ë¹„ìš©
            'monthly_breakdown': [
                {'month': row[0], 'records': row[1], 'avg_file_size': row[2]}
                for row in monthly_data
            ]
        }


def setup_auto_cleanup():
    """ìë™ ì •ë¦¬ ì„¤ì • (cron jobìš©)"""
    manager = DataManager()
    
    # ë§¤ì£¼ ì •ë¦¬
    print("ğŸ”„ ì£¼ê°„ ìë™ ì •ë¦¬ ì‹œì‘...")
    stats = manager.optimize_storage()
    
    # ë§¤ì›” ë°±ì—…
    if datetime.now().day == 1:  # ë§¤ì›” 1ì¼
        print("ğŸ“¦ ì›”ê°„ ë°±ì—… ì‹œì‘...")
        manager.export_and_compress()
    
    return stats


if __name__ == "__main__":
    manager = DataManager()
    
    print("=" * 50)
    print("ğŸ’¾ SongLab ë°ì´í„° ê´€ë¦¬ ì‹œìŠ¤í…œ")
    print("=" * 50)
    
    # í˜„ì¬ ìŠ¤í† ë¦¬ì§€ ìƒíƒœ
    stats = manager.get_storage_stats()
    print(f"ğŸ“Š í˜„ì¬ ìƒíƒœ:")
    print(f"   ì´ ë ˆì½”ë“œ: {stats['total_records']:,}ê°œ")
    print(f"   DB í¬ê¸°: {stats['current_db_size_mb']:.2f}MB")
    print(f"   ì›” ì˜ˆìƒ ì¦ê°€: {stats['estimated_monthly_growth_mb']:.2f}MB")
    print(f"   ë…„ ì˜ˆìƒ ë¹„ìš©: ${stats['estimated_yearly_cost_usd']:.2f}")
    
    # ìµœì í™” ì‹¤í–‰
    print(f"\nğŸ› ï¸  ìµœì í™” ì‹¤í–‰:")
    result = manager.optimize_storage()
    
    print(f"\nğŸ’¡ ë¹„ìš© ì ˆì•½ íŒ:")
    print(f"   â€¢ 90ì¼ ì´ìƒ ëœ ë°ì´í„° ìë™ ì‚­ì œ")
    print(f"   â€¢ ì¤‘ë³µ íŒŒì¼ ìë™ ì œê±°") 
    print(f"   â€¢ ì••ì¶• ë°±ì—…ìœ¼ë¡œ 90% ìš©ëŸ‰ ì ˆì•½")
    print(f"   â€¢ ì‹¤ì œ ì„œë²„ ë¹„ìš©: ì›” $1 ì´í•˜ ì˜ˆìƒ")