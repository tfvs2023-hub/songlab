"""
ê²½ëŸ‰ ë³´ì»¬ ë¶„ì„ê¸° - ê°„ì†Œí™” ë²„ì „ (FFmpeg ë¼ìš°ë“œë‹ˆìŠ¤ ì²˜ë¦¬ ì œì™¸)
"""

import numpy as np
import librosa
import soundfile as sf
import subprocess
import tempfile
import os
from scipy.stats import linregress
import warnings
warnings.filterwarnings('ignore')

def convert_m4a_to_wav(m4a_path):
    """M4Aë¥¼ WAVë¡œ ë³€í™˜ (ê°„ë‹¨ ë²„ì „)"""
    try:
        temp_wav = tempfile.NamedTemporaryFile(suffix='.wav', delete=False)
        temp_wav_path = temp_wav.name
        temp_wav.close()
        
        cmd = [
            'ffmpeg', '-i', m4a_path,
            '-ac', '1',  # ëª¨ë…¸
            '-ar', '16000',  # 16kHz
            temp_wav_path, '-y'
        ]
        
        result = subprocess.run(cmd, capture_output=True, text=True)
        
        if result.returncode != 0:
            return None
            
        return temp_wav_path
        
    except Exception as e:
        return None

def simple_preprocess(audio_file):
    """ê°„ë‹¨í•œ ì „ì²˜ë¦¬"""
    try:
        if audio_file.endswith('.m4a'):
            wav_path = convert_m4a_to_wav(audio_file)
            if wav_path:
                audio, sr = sf.read(wav_path)
                os.unlink(wav_path)
            else:
                audio, sr = sf.read(audio_file)
        else:
            audio, sr = sf.read(audio_file)
        
        # ëª¨ë…¸ ë³€í™˜
        if len(audio.shape) > 1:
            audio = np.mean(audio, axis=1)
        
        # 16kHz ë¦¬ìƒ˜í”Œë§
        if sr != 16000:
            audio = librosa.resample(y=audio, orig_sr=sr, target_sr=16000)
            sr = 16000
        
        # ê°„ë‹¨í•œ ì •ê·œí™”
        audio = audio / (np.max(np.abs(audio)) + 1e-10)
        
        return audio, sr
        
    except Exception as e:
        print(f"ì „ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
        return None, None

def extract_representative_chunks(audio, sr, num_chunks=12, top_chunks=6, chunk_duration=10):
    """ëŒ€í‘œ ìƒ˜í”Œ ì¶”ì¶œ"""
    try:
        total_duration = len(audio) / sr
        chunk_samples = chunk_duration * sr
        
        chunks = []
        for i in range(num_chunks):
            start_time = i * total_duration / num_chunks
            start_sample = int(start_time * sr)
            end_sample = min(start_sample + chunk_samples, len(audio))
            
            if end_sample - start_sample < sr:  # 1ì´ˆ ë¯¸ë§Œì´ë©´ ìŠ¤í‚µ
                continue
            
            chunk_audio = audio[start_sample:end_sample]
            
            # ê°„ë‹¨í•œ í’ˆì§ˆ ì ìˆ˜ (RMS + í”¼ì¹˜ ì•ˆì •ì„±)
            rms = np.sqrt(np.mean(chunk_audio ** 2))
            
            # ìê¸°ìƒê´€ìœ¼ë¡œ í”¼ì¹˜ ì•ˆì •ì„± ì¶”ì •
            autocorr = np.correlate(chunk_audio, chunk_audio, mode='full')
            autocorr = autocorr[len(autocorr)//2:]
            
            if len(autocorr) > sr//50:  # 20Hz ì´í•˜ í™•ì¸
                max_corr = np.max(autocorr[sr//400:sr//50])  # 50-400Hz ë²”ìœ„
                pitch_stability = max_corr / (autocorr[0] + 1e-10)
            else:
                pitch_stability = 0.1
            
            score = 0.7 * pitch_stability + 0.3 * rms
            
            chunks.append({
                'audio': chunk_audio,
                'score': score,
                'rms': rms,
                'pitch_stability': pitch_stability
            })
        
        # ìƒìœ„ chunks ì„ íƒ
        chunks.sort(key=lambda x: x['score'], reverse=True)
        return chunks[:top_chunks]
        
    except Exception as e:
        print(f"ì²­í¬ ì¶”ì¶œ ì˜¤ë¥˜: {e}")
        return []

def calculate_light_features(audio, sr):
    """ê²½ëŸ‰ íŠ¹ì§• ì¶”ì¶œ"""
    try:
        features = {}
        
        # 1. ê°„ë‹¨í•œ HNR (ìê¸°ìƒê´€ ê¸°ë°˜)
        autocorr = np.correlate(audio, audio, mode='full')
        autocorr = autocorr[len(autocorr)//2:]
        
        if len(autocorr) > sr//50:
            max_corr = np.max(autocorr[sr//400:sr//50])
            noise_level = 1 - max_corr / (autocorr[0] + 1e-10)
            hnr = 10 * np.log10((max_corr + 1e-10) / (noise_level + 1e-10))
            features['hnr'] = max(0, min(30, hnr))
        else:
            features['hnr'] = 10.0
        
        # 2. Spectral Tilt (300Hz-3kHz)
        fft = np.fft.rfft(audio)
        freqs = np.fft.rfftfreq(len(audio), 1/sr)
        magnitude = np.abs(fft) + 1e-10
        
        mask = (freqs >= 300) & (freqs <= 3000)
        if np.sum(mask) > 10:
            freq_range = freqs[mask]
            mag_range = magnitude[mask]
            log_mag = 20 * np.log10(mag_range)
            log_freq = np.log10(freq_range)
            
            slope, _, _, _, _ = linregress(log_freq, log_mag)
            features['spectral_tilt'] = slope * np.log10(2)  # dB/octave
        else:
            features['spectral_tilt'] = -5.0
        
        # 3. Spectral Flatness
        geometric_mean = np.exp(np.mean(np.log(magnitude)))
        arithmetic_mean = np.mean(magnitude)
        features['spectral_flatness'] = geometric_mean / (arithmetic_mean + 1e-10)
        
        # 4. ZCR (ê°„ì ‘ì ì¸ ë…¸ì´ì¦ˆ ì§€í‘œ)
        zcr = librosa.feature.zero_crossing_rate(audio)[0]
        features['zcr'] = np.mean(zcr)
        
        # 5. Spectral Centroid
        centroid = librosa.feature.spectral_centroid(y=audio, sr=sr)[0]
        features['spectral_centroid'] = np.mean(centroid)
        
        return features
        
    except Exception as e:
        print(f"íŠ¹ì§• ì¶”ì¶œ ì˜¤ë¥˜: {e}")
        return {}

def calculate_clarity_score(all_features, source_hint="unknown"):
    """ì„ ëª…ë„ ì ìˆ˜ ê³„ì‚°"""
    try:
        # íŠ¹ì§•ë“¤ì˜ í‰ê·  ê³„ì‚°
        feature_means = {}
        feature_names = ['hnr', 'spectral_tilt', 'spectral_flatness', 'zcr', 'spectral_centroid']
        
        for name in feature_names:
            values = [f.get(name, 0) for f in all_features if name in f]
            feature_means[name] = np.mean(values) if values else 0
        
        # ì†ŒìŠ¤ ë³´ì •
        if source_hint == "kakaotalk":
            feature_means['hnr'] -= 1.0  # ì¹´í†¡ì€ HNR ë‚®ê²Œ ë³´ì •
            feature_means['spectral_flatness'] += 0.02
        
        # ì„ ëª…ë„ ê³„ì‚° (ê²½í—˜ì  ê³µì‹)
        hnr_score = (feature_means['hnr'] - 15) * 2  # HNR 15dB ê¸°ì¤€
        tilt_score = -(feature_means['spectral_tilt'] + 8) * 3  # Tilt -8 ê¸°ì¤€  
        flatness_score = -(feature_means['spectral_flatness'] - 0.25) * 100  # 0.25 ê¸°ì¤€
        zcr_score = -(feature_means['zcr'] - 0.1) * 200  # 0.1 ê¸°ì¤€
        
        clarity = hnr_score + tilt_score + flatness_score + zcr_score
        
        # 0-100 ë²”ìœ„ë¡œ ì •ê·œí™”
        clarity_score = np.clip(clarity + 50, 0, 100)
        
        # ê°€ì„±/í—ˆìŠ¤í‚¤ ìºí•‘
        if feature_means['hnr'] < 10:
            clarity_score = min(clarity_score, 60)
        
        # ë“±ê¸‰ ë§¤ê¸°ê¸°
        if clarity_score >= 70:
            grade = "High"
        elif clarity_score >= 40:
            grade = "Medium"
        else:
            grade = "Low"
        
        # íƒœê·¸
        brightness = "ë°ìŒ" if feature_means['spectral_tilt'] > -6 else "ì–´ë‘ì›€"
        roughness = "ê±°ì¹¨" if feature_means['zcr'] > 0.15 or feature_means['hnr'] < 12 else "ë¶€ë“œëŸ¬ì›€"
        
        return {
            'clarity_score': clarity_score,
            'grade': grade,
            'brightness': brightness,
            'roughness': roughness,
            'raw_features': feature_means
        }
        
    except Exception as e:
        print(f"ì ìˆ˜ ê³„ì‚° ì˜¤ë¥˜: {e}")
        return {}

def analyze_vocal_simple(audio_file, source_hint="unknown"):
    """ê°„ë‹¨í•œ ë³´ì»¬ ë¶„ì„"""
    
    filename = audio_file.split('/')[-1].split('\\')[-1]
    print(f"\nğŸ¤ {filename} ë¶„ì„ ì¤‘...")
    
    # 1. ì „ì²˜ë¦¬
    audio, sr = simple_preprocess(audio_file)
    if audio is None:
        print("âŒ ì „ì²˜ë¦¬ ì‹¤íŒ¨")
        return None
    
    print(f"   ğŸ“Š ê¸¸ì´: {len(audio)/sr:.1f}ì´ˆ, SR: {sr}Hz")
    
    # 2. ëŒ€í‘œ ì²­í¬ ì¶”ì¶œ
    chunks = extract_representative_chunks(audio, sr)
    if not chunks:
        print("âŒ ì²­í¬ ì¶”ì¶œ ì‹¤íŒ¨")
        return None
    
    print(f"   ğŸ¯ ìƒìœ„ {len(chunks)}ê°œ ì²­í¬ ì„ íƒ")
    
    # 3. íŠ¹ì§• ì¶”ì¶œ
    all_features = []
    for chunk in chunks:
        features = calculate_light_features(chunk['audio'], sr)
        if features:
            all_features.append(features)
    
    if not all_features:
        print("âŒ íŠ¹ì§• ì¶”ì¶œ ì‹¤íŒ¨")
        return None
    
    # 4. ì ìˆ˜ ê³„ì‚°
    result = calculate_clarity_score(all_features, source_hint)
    
    if result:
        print(f"   âœ… ì„ ëª…ë„: {result['clarity_score']:.1f} ({result['grade']})")
        print(f"   ğŸ·ï¸ íƒœê·¸: {result['brightness']}, {result['roughness']}")
        
        # ì£¼ìš” íŠ¹ì§• ì¶œë ¥
        features = result['raw_features']
        print(f"   ğŸ“ˆ HNR: {features.get('hnr', 0):.1f}dB")
        print(f"   ğŸ“‰ Spectral Tilt: {features.get('spectral_tilt', 0):.1f}dB/oct")
        print(f"   ğŸ“Š Flatness: {features.get('spectral_flatness', 0):.3f}")
    
    return result

def test_all_vocals():
    """ëª¨ë“  ë³´ì»¬ í…ŒìŠ¤íŠ¸"""
    
    print("=" * 70)
    print("ğŸ¤ ê²½ëŸ‰ ë³´ì»¬ ë¶„ì„ê¸° - ê°„ì†Œí™” í…ŒìŠ¤íŠ¸")
    print("=" * 70)
    
    test_files = [
        (r"C:\Users\user\Desktop\vocals_extracted\ê¹€ë²”ìˆ˜_ê¹€ë²”ìˆ˜ - Dear Love_ë³´ì»¬.wav", "unknown"),
        (r"C:\Users\user\Documents\ì¹´ì¹´ì˜¤í†¡ ë°›ì€ íŒŒì¼\kakaotalk_1756474302376.m4a", "kakaotalk"),
        (r"C:\Users\user\Desktop\vocals_extracted\ë¡œì´í‚´_ë¡œì´í‚´ - As Is_ë³´ì»¬.wav", "unknown"),
        (r"C:\Users\user\Documents\ì†Œë¦¬ ë…¹ìŒ\ê°€ì„±_ê°€ì„±ë¹„ë¸Œë¼í† .wav", "unknown")
    ]
    
    results = []
    
    for audio_file, source_hint in test_files:
        result = analyze_vocal_simple(audio_file, source_hint)
        if result:
            filename = audio_file.split('/')[-1].split('\\')[-1]
            results.append({
                'file': filename[:20],
                'score': result['clarity_score'],
                'grade': result['grade'],
                'brightness': result['brightness'],
                'roughness': result['roughness']
            })
    
    # ìµœì¢… ê²°ê³¼
    if results:
        print("\n" + "=" * 70)
        print("ğŸ† ìµœì¢… ê²°ê³¼")
        print("=" * 70)
        
        print(f"\n{'íŒŒì¼':<22} | {'ì„ ëª…ë„':<6} | {'ë“±ê¸‰':<6} | {'ë°ê¸°':<6} | {'ê±°ì¹¨':<6}")
        print("-" * 65)
        
        for r in results:
            print(f"{r['file']:<22} | {r['score']:<6.1f} | {r['grade']:<6} | {r['brightness']:<6} | {r['roughness']:<6}")
        
        print(f"\nğŸ’¡ ì˜ˆìƒ ìˆœì„œ: ê¹€ë²”ìˆ˜ > kakaotalk > ë¡œì´í‚´ > ê°€ì„±")
        sorted_results = sorted(results, key=lambda x: x['score'], reverse=True)
        actual_order = " > ".join([r['file'][:10] for r in sorted_results])
        print(f"ğŸ’¡ ì‹¤ì œ ìˆœì„œ: {actual_order}")

if __name__ == "__main__":
    test_all_vocals()