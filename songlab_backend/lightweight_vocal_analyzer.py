"""
ê²½ëŸ‰ ë³´ì»¬ ë¶„ì„ê¸° - ì „ì—­ ì„ ëª…ë„/ë°ê¸°/ê±°ì¹¨ ë¶„ì„
ëª©í‘œí•œ íŒŒì´í”„ë¼ì¸ êµ¬í˜„
"""

import numpy as np
import librosa
import soundfile as sf
import subprocess
import tempfile
import os
from scipy import signal
from scipy.stats import linregress
import warnings
warnings.filterwarnings('ignore')

class LightweightVocalAnalyzer:
    def __init__(self):
        self.target_sr = 16000
        self.target_lufs = -23
        self.chunk_duration = 10  # seconds
        self.num_chunks = 12
        self.top_chunks = 6
        
    def preprocess_audio(self, audio_file):
        """ì „ì²˜ë¦¬: ëª¨ë…¸, 16kHz, -23 LUFS ë¼ìš°ë“œë‹ˆìŠ¤ ë§¤ì¹­"""
        try:
            print("ğŸ”§ ì „ì²˜ë¦¬ ì¤‘...")
            
            # ì„ì‹œ íŒŒì¼ ìƒì„±
            temp_processed = tempfile.NamedTemporaryFile(suffix='.wav', delete=False)
            temp_processed_path = temp_processed.name
            temp_processed.close()
            
            # FFmpegë¡œ ì „ì²˜ë¦¬
            cmd = [
                'ffmpeg', '-i', audio_file,
                '-ac', '1',  # ëª¨ë…¸
                '-ar', '16000',  # 16kHz
                '-af', f'loudnorm=I={self.target_lufs}:TP=-1.5:LRA=11',  # ë¼ìš°ë“œë‹ˆìŠ¤ ë§¤ì¹­
                temp_processed_path, '-y'
            ]
            
            result = subprocess.run(cmd, capture_output=True, text=True)
            
            if result.returncode != 0:
                print(f"   âŒ FFmpeg ì „ì²˜ë¦¬ ì‹¤íŒ¨: {result.stderr}")
                return None
            
            # ì²˜ë¦¬ëœ ì˜¤ë””ì˜¤ ë¡œë“œ
            audio, sr = sf.read(temp_processed_path)
            os.unlink(temp_processed_path)
            
            print(f"   âœ… ì „ì²˜ë¦¬ ì™„ë£Œ: {len(audio)/sr:.1f}ì´ˆ, {sr}Hz")
            return audio, sr
            
        except Exception as e:
            print(f"   âŒ ì „ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
            return None, None
    
    def simple_vad(self, audio, sr):
        """ê°„ë‹¨í•œ VAD - ìœ ì„± êµ¬ê°„ íƒì§€"""
        try:
            # Energy + ZCR í•˜ì´ë¸Œë¦¬ë“œ
            frame_length = int(0.02 * sr)  # 20ms
            hop_length = int(0.01 * sr)    # 10ms
            
            # RMS Energy
            rms = librosa.feature.rms(y=audio, frame_length=frame_length, hop_length=hop_length)[0]
            
            # Zero Crossing Rate
            zcr = librosa.feature.zero_crossing_rate(audio, frame_length=frame_length, hop_length=hop_length)[0]
            
            # ì„ê³„ê°’ ê¸°ë°˜ ìœ ì„± íŒì •
            energy_threshold = np.percentile(rms, 30)  # í•˜ìœ„ 30% ì´ìƒ
            zcr_threshold = 0.1  # ZCR 10% ì´í•˜
            
            voiced = (rms > energy_threshold) & (zcr < zcr_threshold)
            voiced_ratio = np.mean(voiced)
            
            print(f"   ğŸ“Š ìœ ì„± ë¹„ìœ¨: {voiced_ratio:.1%}")
            
            # ì‹ ë¢°ë„ í”Œë˜ê·¸
            confidence = "High"
            if voiced_ratio < 0.25:
                confidence = "Low"
                print(f"   âš ï¸ ìœ ì„± ë¹„ìœ¨ì´ ë‚®ìŒ - ì‹ ë¢°ë„: {confidence}")
            
            return voiced, voiced_ratio, confidence
            
        except Exception as e:
            print(f"   âŒ VAD ì˜¤ë¥˜: {e}")
            return np.ones(len(audio) // hop_length, dtype=bool), 1.0, "Low"
    
    def extract_representative_samples(self, audio, sr, voiced_frames):
        """ëŒ€í‘œ ìƒ˜í”Œ ì¶”ì¶œ - ìƒìœ„ 6ê°œ 10ì´ˆ êµ¬ê°„"""
        try:
            print("ğŸ¯ ëŒ€í‘œ ìƒ˜í”Œ ì¶”ì¶œ ì¤‘...")
            
            total_duration = len(audio) / sr
            chunk_samples = self.chunk_duration * sr
            
            chunks = []
            for i in range(self.num_chunks):
                start_time = i * total_duration / self.num_chunks
                start_sample = int(start_time * sr)
                end_sample = min(start_sample + chunk_samples, len(audio))
                
                if end_sample - start_sample < sr:  # 1ì´ˆ ë¯¸ë§Œì´ë©´ ìŠ¤í‚µ
                    continue
                
                chunk_audio = audio[start_sample:end_sample]
                
                # F0 confidence (ê°„ë‹¨í•œ ìê¸°ìƒê´€ ê¸°ë°˜)
                f0_conf = self.calculate_f0_confidence(chunk_audio, sr)
                
                # RMS normalization
                rms_norm = np.sqrt(np.mean(chunk_audio ** 2))
                
                # Score ê³„ì‚°
                score = 0.7 * f0_conf + 0.3 * rms_norm
                
                chunks.append({
                    'start_sample': start_sample,
                    'end_sample': end_sample,
                    'audio': chunk_audio,
                    'f0_conf': f0_conf,
                    'rms_norm': rms_norm,
                    'score': score
                })
            
            # ìƒìœ„ 6ê°œ ì„ íƒ
            chunks.sort(key=lambda x: x['score'], reverse=True)
            top_chunks = chunks[:self.top_chunks]
            
            print(f"   âœ… {len(chunks)}ê°œ ì¤‘ ìƒìœ„ {len(top_chunks)}ê°œ ì„ íƒ")
            for i, chunk in enumerate(top_chunks[:3]):  # ìƒìœ„ 3ê°œë§Œ ì¶œë ¥
                print(f"      #{i+1}: Score={chunk['score']:.3f} (F0={chunk['f0_conf']:.3f}, RMS={chunk['rms_norm']:.3f})")
            
            return top_chunks
            
        except Exception as e:
            print(f"   âŒ ëŒ€í‘œ ìƒ˜í”Œ ì¶”ì¶œ ì˜¤ë¥˜: {e}")
            return []
    
    def calculate_f0_confidence(self, audio, sr):
        """F0 confidence ê³„ì‚° (ê°„ë‹¨í•œ ìê¸°ìƒê´€ ê¸°ë°˜)"""
        try:
            # ìê¸°ìƒê´€ ê³„ì‚°
            autocorr = np.correlate(audio, audio, mode='full')
            autocorr = autocorr[len(autocorr)//2:]
            
            # í”¼í¬ ì°¾ê¸° (80-800Hz ë²”ìœ„)
            min_period = sr // 800  # 800Hz
            max_period = sr // 80   # 80Hz
            
            if max_period >= len(autocorr):
                return 0.1
            
            search_range = autocorr[min_period:max_period]
            if len(search_range) == 0:
                return 0.1
            
            max_corr = np.max(search_range)
            normalized_corr = max_corr / autocorr[0] if autocorr[0] > 0 else 0
            
            return max(0.1, min(1.0, normalized_corr))
            
        except Exception as e:
            return 0.1
    
    def extract_light_features(self, chunk_audio, sr):
        """ë¼ì´íŠ¸ íŠ¹ì§• ì¶”ì¶œ"""
        try:
            features = {}
            
            # 1. CPP (Cepstral Peak Prominence) - ê°„ì´ ë²„ì „
            features['cpp'] = self.calculate_cpp_simple(chunk_audio, sr)
            
            # 2. HNR (Harmonics-to-Noise Ratio) - ìê¸°ìƒê´€ ê¸°ë°˜
            features['hnr'] = self.calculate_hnr_simple(chunk_audio, sr)
            
            # 3. Spectral Tilt (300Hz-3kHz ì§ì„  íšŒê·€)
            features['spectral_tilt'] = self.calculate_spectral_tilt(chunk_audio, sr)
            
            # 4. Spectral Flatness (0~1)
            features['spectral_flatness'] = self.calculate_spectral_flatness(chunk_audio, sr)
            
            # 5. F0 confidence
            features['f0_confidence'] = self.calculate_f0_confidence(chunk_audio, sr)
            
            # 6. Aperiodicity proxy (ê°„ë‹¨í•œ jitter ëŒ€ìš©)
            features['aperiodicity'] = self.calculate_aperiodicity_simple(chunk_audio, sr)
            
            # 7. ë³´ì¡° íŠ¹ì§•ë“¤
            features['spectral_centroid'] = self.calculate_spectral_centroid(chunk_audio, sr)
            features['spectral_rolloff'] = self.calculate_spectral_rolloff(chunk_audio, sr)
            
            return features
            
        except Exception as e:
            print(f"   âŒ íŠ¹ì§• ì¶”ì¶œ ì˜¤ë¥˜: {e}")
            return {}
    
    def calculate_cpp_simple(self, audio, sr):
        """ê°„ì´ CPP ê³„ì‚°"""
        try:
            # ìœˆë„ìš° 40ms
            frame_length = int(0.04 * sr)
            
            # FFT
            fft = np.fft.fft(audio[:frame_length] * np.hanning(frame_length))
            log_spectrum = np.log(np.abs(fft) + 1e-10)
            
            # Cepstrum
            cepstrum = np.fft.ifft(log_spectrum).real
            
            # í”¼ì¹˜ ë²”ìœ„ì—ì„œ í”¼í¬ ì°¾ê¸° (2-20ms, 50-500Hz)
            min_quefrency = int(sr * 0.002)  # 2ms
            max_quefrency = int(sr * 0.02)   # 20ms
            
            if max_quefrency >= len(cepstrum):
                return 5.0
            
            pitch_cepstrum = cepstrum[min_quefrency:max_quefrency]
            
            if len(pitch_cepstrum) == 0:
                return 5.0
            
            # ìµœëŒ€ í”¼í¬ì™€ ì£¼ë³€ í‰ê· ì˜ ì°¨ì´
            max_peak = np.max(pitch_cepstrum)
            mean_around = np.mean(pitch_cepstrum)
            
            cpp = max_peak - mean_around
            return max(0, cpp * 1000)  # dB ìŠ¤ì¼€ì¼ë¡œ ë³€í™˜
            
        except Exception as e:
            return 5.0
    
    def calculate_hnr_simple(self, audio, sr):
        """ê°„ì´ HNR ê³„ì‚°"""
        try:
            # ìê¸°ìƒê´€ ê¸°ë°˜ HNR
            autocorr = np.correlate(audio, audio, mode='full')
            autocorr = autocorr[len(autocorr)//2:]
            
            if len(autocorr) < 2:
                return 10.0
            
            # ì •ê·œí™”
            if autocorr[0] > 0:
                autocorr = autocorr / autocorr[0]
            else:
                return 10.0
            
            # í”¼í¬ ì°¾ê¸°
            min_period = sr // 500
            max_period = sr // 100
            
            if max_period >= len(autocorr):
                max_period = len(autocorr) - 1
                
            if min_period >= max_period:
                return 10.0
            
            search_range = autocorr[min_period:max_period]
            
            if len(search_range) == 0:
                return 10.0
            
            max_corr = np.max(search_range)
            noise_level = 1 - max_corr
            
            if noise_level <= 0.001:
                return 30.0
                
            hnr = 10 * np.log10(max_corr / noise_level)
            return max(0, hnr)
            
        except Exception as e:
            return 10.0
    
    def calculate_spectral_tilt(self, audio, sr):
        """Spectral Tilt (300Hz-3kHz ì§ì„  íšŒê·€)"""
        try:
            # FFT
            fft = np.fft.rfft(audio)
            freqs = np.fft.rfftfreq(len(audio), 1/sr)
            magnitude = np.abs(fft)
            
            # 300Hz-3kHz ë²”ìœ„
            mask = (freqs >= 300) & (freqs <= 3000)
            
            if np.sum(mask) < 10:  # ìµœì†Œ 10ê°œ ì ì€ ìˆì–´ì•¼ í•¨
                return -5.0
            
            freq_range = freqs[mask]
            mag_range = magnitude[mask]
            
            # ë¡œê·¸ ìŠ¤ì¼€ì¼
            log_mag = 20 * np.log10(mag_range + 1e-10)
            log_freq = np.log10(freq_range)
            
            # ì„ í˜• íšŒê·€
            slope, intercept, r_value, p_value, std_err = linregress(log_freq, log_mag)
            
            # dB/octaveë¡œ ë³€í™˜ (octave = log2, ìš°ë¦¬ëŠ” log10 ì‚¬ìš©)
            db_per_octave = slope * np.log10(2)
            
            return db_per_octave
            
        except Exception as e:
            return -5.0
    
    def calculate_spectral_flatness(self, audio, sr):
        """Spectral Flatness ê³„ì‚°"""
        try:
            # FFT
            fft = np.fft.rfft(audio)
            magnitude = np.abs(fft) + 1e-10
            
            # Geometric mean / Arithmetic mean
            geometric_mean = np.exp(np.mean(np.log(magnitude)))
            arithmetic_mean = np.mean(magnitude)
            
            if arithmetic_mean == 0:
                return 0.5
            
            flatness = geometric_mean / arithmetic_mean
            return min(1.0, flatness)
            
        except Exception as e:
            return 0.5
    
    def calculate_aperiodicity_simple(self, audio, sr):
        """ê°„ë‹¨í•œ ë¹„ì£¼ê¸°ì„± ì¸¡ì •"""
        try:
            # ì—°ì†ëœ í”„ë ˆì„ë“¤ì˜ RMS ë³€ë™ì„±
            frame_length = int(0.01 * sr)  # 10ms
            
            if len(audio) < frame_length * 3:
                return 0.1
            
            frames_rms = []
            for i in range(0, len(audio) - frame_length, frame_length):
                frame = audio[i:i+frame_length]
                rms = np.sqrt(np.mean(frame**2))
                frames_rms.append(rms)
            
            if len(frames_rms) < 2:
                return 0.1
            
            # RMSì˜ ë³€ë™ ê³„ìˆ˜ (CV)
            mean_rms = np.mean(frames_rms)
            std_rms = np.std(frames_rms)
            
            if mean_rms == 0:
                return 0.1
            
            cv = std_rms / mean_rms
            return min(1.0, cv)
            
        except Exception as e:
            return 0.1
    
    def calculate_spectral_centroid(self, audio, sr):
        """Spectral Centroid ê³„ì‚°"""
        try:
            centroid = librosa.feature.spectral_centroid(y=audio, sr=sr)[0]
            return np.mean(centroid)
        except:
            return 1500.0
    
    def calculate_spectral_rolloff(self, audio, sr):
        """Spectral Rolloff ê³„ì‚° (85%)"""
        try:
            rolloff = librosa.feature.spectral_rolloff(y=audio, sr=sr, roll_percent=0.85)[0]
            return np.mean(rolloff)
        except:
            return 3000.0
    
    def aggregate_features(self, all_features):
        """íŠ¹ì§• ì§‘ê³„ - mean, p90, IQR"""
        try:
            print("ğŸ“Š íŠ¹ì§• ì§‘ê³„ ì¤‘...")
            
            aggregated = {}
            
            # ëª¨ë“  íŠ¹ì§•ì˜ ì´ë¦„ ìˆ˜ì§‘
            feature_names = set()
            for features in all_features:
                feature_names.update(features.keys())
            
            for name in feature_names:
                values = [f.get(name, 0) for f in all_features if name in f]
                
                if values:
                    aggregated[f'{name}_mean'] = np.mean(values)
                    aggregated[f'{name}_p90'] = np.percentile(values, 90)
                    aggregated[f'{name}_iqr'] = np.percentile(values, 75) - np.percentile(values, 25)
                else:
                    aggregated[f'{name}_mean'] = 0
                    aggregated[f'{name}_p90'] = 0
                    aggregated[f'{name}_iqr'] = 0
            
            print(f"   âœ… {len(feature_names)}ê°œ íŠ¹ì§•ì—ì„œ {len(aggregated)}ê°œ í†µê³„ ìƒì„±")
            return aggregated
            
        except Exception as e:
            print(f"   âŒ íŠ¹ì§• ì§‘ê³„ ì˜¤ë¥˜: {e}")
            return {}
    
    def apply_source_correction(self, features, source_hint="unknown"):
        """ì†ŒìŠ¤ ë³´ì • í…Œì´ë¸” ì ìš©"""
        try:
            print(f"ğŸ”§ ì†ŒìŠ¤ ë³´ì • ì ìš©: {source_hint}")
            
            corrections = {
                "kakaotalk": {
                    "hnr_mean": -1.0,
                    "spectral_tilt_mean": +0.5,
                    "spectral_flatness_mean": +0.02
                },
                "instagram": {
                    "cpp_mean": -0.8
                },
                "low_quality": {
                    "hnr_mean": -2.0,
                    "spectral_flatness_mean": +0.05
                }
            }
            
            if source_hint in corrections:
                correction_table = corrections[source_hint]
                for key, correction in correction_table.items():
                    if key in features:
                        old_value = features[key]
                        features[key] += correction
                        print(f"   {key}: {old_value:.2f} â†’ {features[key]:.2f} ({correction:+.2f})")
            
            return features
            
        except Exception as e:
            print(f"   âŒ ì†ŒìŠ¤ ë³´ì • ì˜¤ë¥˜: {e}")
            return features
    
    def calculate_final_scores(self, features):
        """ìµœì¢… ìŠ¤ì½”ì–´ë§"""
        try:
            print("ğŸ¯ ìµœì¢… ì ìˆ˜ ê³„ì‚° ì¤‘...")
            
            # Z-score ì •ê·œí™”ë¥¼ ìœ„í•œ ê¸°ì¤€ê°’ë“¤ (ê²½í—˜ì  ì„¤ì •)
            reference_stats = {
                'cpp_mean': {'mean': 8.0, 'std': 2.0},
                'hnr_mean': {'mean': 15.0, 'std': 5.0},
                'spectral_tilt_mean': {'mean': -8.0, 'std': 3.0},
                'spectral_flatness_mean': {'mean': 0.25, 'std': 0.1},
                'f0_confidence_mean': {'mean': 0.6, 'std': 0.2},
                'aperiodicity_mean': {'mean': 0.3, 'std': 0.2}
            }
            
            # Z-score ê³„ì‚°
            z_scores = {}
            for key, ref in reference_stats.items():
                if key in features:
                    z_scores[key] = (features[key] - ref['mean']) / ref['std']
                else:
                    z_scores[key] = 0
            
            # ì„ ëª…ë„ ê³„ì‚°
            clarity = (z_scores['cpp_mean'] + 
                      z_scores['hnr_mean'] - 
                      z_scores['spectral_tilt_mean'] - 
                      z_scores['spectral_flatness_mean'] + 
                      0.5 * z_scores['f0_confidence_mean'] - 
                      0.5 * z_scores['aperiodicity_mean'])
            
            # 0-100ìœ¼ë¡œ ì„ í˜• ë§¤í•‘ (z-score -3~+3ì„ 0~100ìœ¼ë¡œ)
            clarity_score = np.clip((clarity + 3) * 100 / 6, 0, 100)
            
            # ê°€ì„±/ìˆ¨ì„ì„ ìº¡ ì ìš©
            if features.get('hnr_mean', 15) < 10:
                clarity_score = min(clarity_score, 60)
                print("   âš ï¸ ë‚®ì€ HNRë¡œ ì¸í•œ ì„ ëª…ë„ ìºí•‘ ì ìš©")
            
            # ë“±ê¸‰í™”
            if clarity_score >= 70:
                grade = "High"
            elif clarity_score >= 40:
                grade = "Medium"  
            else:
                grade = "Low"
            
            # ë³´ì¡° íƒœê·¸
            brightness_tag = "ë°ìŒ" if z_scores['spectral_tilt_mean'] > 0 else "ì–´ë‘ì›€"
            roughness_tag = "ê±°ì¹¨" if (z_scores['aperiodicity_mean'] > 0.5 or z_scores['hnr_mean'] < -0.5) else "ë¶€ë“œëŸ¬ì›€"
            
            results = {
                'clarity_score': clarity_score,
                'clarity_grade': grade,
                'brightness_tag': brightness_tag,
                'roughness_tag': roughness_tag,
                'z_scores': z_scores,
                'raw_features': features
            }
            
            print(f"   âœ… ì„ ëª…ë„: {clarity_score:.1f} ({grade})")
            print(f"   íƒœê·¸: {brightness_tag}, {roughness_tag}")
            
            return results
            
        except Exception as e:
            print(f"   âŒ ìµœì¢… ì ìˆ˜ ê³„ì‚° ì˜¤ë¥˜: {e}")
            return {}
    
    def analyze_file(self, audio_file, source_hint="unknown"):
        """ë©”ì¸ ë¶„ì„ í•¨ìˆ˜"""
        print("=" * 70)
        print("ğŸ¤ ê²½ëŸ‰ ë³´ì»¬ ë¶„ì„ê¸° - ì „ì—­ í’ˆì§ˆ ë¶„ì„")
        print("=" * 70)
        print(f"ğŸ“ íŒŒì¼: {audio_file.split('/')[-1].split('\\')[-1]}")
        
        # 1. ì „ì²˜ë¦¬
        audio, sr = self.preprocess_audio(audio_file)
        if audio is None:
            return None
        
        # 2. VAD
        voiced_frames, voiced_ratio, vad_confidence = self.simple_vad(audio, sr)
        
        # 3. ëŒ€í‘œ ìƒ˜í”Œ ì¶”ì¶œ
        chunks = self.extract_representative_samples(audio, sr, voiced_frames)
        if not chunks:
            print("âŒ ëŒ€í‘œ ìƒ˜í”Œ ì¶”ì¶œ ì‹¤íŒ¨")
            return None
        
        # 4. íŠ¹ì§• ì¶”ì¶œ
        print("ğŸ” ë¼ì´íŠ¸ íŠ¹ì§• ì¶”ì¶œ ì¤‘...")
        all_features = []
        for i, chunk in enumerate(chunks):
            features = self.extract_light_features(chunk['audio'], sr)
            if features:
                all_features.append(features)
        
        if not all_features:
            print("âŒ íŠ¹ì§• ì¶”ì¶œ ì‹¤íŒ¨")
            return None
        
        # 5. íŠ¹ì§• ì§‘ê³„
        aggregated_features = self.aggregate_features(all_features)
        
        # 6. ì†ŒìŠ¤ ë³´ì •
        corrected_features = self.apply_source_correction(aggregated_features, source_hint)
        
        # 7. ìµœì¢… ìŠ¤ì½”ì–´ë§
        results = self.calculate_final_scores(corrected_features)
        
        # ì‹ ë¢°ë„ ì¶”ê°€
        results['confidence'] = vad_confidence
        results['voiced_ratio'] = voiced_ratio
        results['num_chunks_used'] = len(chunks)
        
        return results

def test_lightweight_analyzer():
    """ê²½ëŸ‰ ë¶„ì„ê¸° í…ŒìŠ¤íŠ¸"""
    
    analyzer = LightweightVocalAnalyzer()
    
    # í…ŒìŠ¤íŠ¸ íŒŒì¼ë“¤
    test_files = [
        (r"C:\Users\user\Desktop\vocals_extracted\ê¹€ë²”ìˆ˜_ê¹€ë²”ìˆ˜ - Dear Love_ë³´ì»¬.wav", "unknown"),
        (r"C:\Users\user\Documents\ì¹´ì¹´ì˜¤í†¡ ë°›ì€ íŒŒì¼\kakaotalk_1756474302376.m4a", "kakaotalk"),
        (r"C:\Users\user\Desktop\vocals_extracted\ë¡œì´í‚´_ë¡œì´í‚´ - As Is_ë³´ì»¬.wav", "unknown"),
        (r"C:\Users\user\Documents\ì†Œë¦¬ ë…¹ìŒ\ê°€ì„±_ê°€ì„±ë¹„ë¸Œë¼í† .wav", "unknown")
    ]
    
    results_summary = []
    
    for audio_file, source_hint in test_files:
        filename = audio_file.split('/')[-1].split('\\')[-1]
        print(f"\n{'='*20} {filename} {'='*20}")
        
        result = analyzer.analyze_file(audio_file, source_hint)
        
        if result:
            results_summary.append({
                'file': filename,
                'clarity_score': result['clarity_score'],
                'grade': result['clarity_grade'],
                'brightness': result['brightness_tag'],
                'roughness': result['roughness_tag'],
                'confidence': result['confidence']
            })
            print("âœ… ë¶„ì„ ì™„ë£Œ!")
        else:
            print("âŒ ë¶„ì„ ì‹¤íŒ¨!")
    
    # ìµœì¢… ë¹„êµ
    if results_summary:
        print("\n" + "=" * 70)
        print("ğŸ† ìµœì¢… ë¹„êµ ê²°ê³¼")
        print("=" * 70)
        
        print(f"\n{'íŒŒì¼':<25} | {'ì„ ëª…ë„':<6} | {'ë“±ê¸‰':<6} | {'ë°ê¸°':<6} | {'ê±°ì¹¨':<6} | ì‹ ë¢°ë„")
        print("-" * 75)
        
        for r in results_summary:
            print(f"{r['file'][:24]:<25} | {r['clarity_score']:<6.1f} | {r['grade']:<6} | {r['brightness']:<6} | {r['roughness']:<6} | {r['confidence']}")

if __name__ == "__main__":
    test_lightweight_analyzer()